{
 "cells": [
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import visdom\n",
    "\n",
    "vis = visdom.Visdom()\n",
    "vis.close(env=\"main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define value tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_tracker(value_plot, value, num):\n",
    "    '''num, loss_value, are Tensor'''\n",
    "    vis.line(X=num,\n",
    "             Y=value,\n",
    "             win=value_plot,\n",
    "             update='append'\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "torch.manual_seed(777)\n",
    "if device =='cuda':\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "\n",
    "How to Calculate mean and std in Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "(50000, 32, 32, 3)\n",
      "[125.30691805 122.95039414 113.86538318]\n",
      "[62.99321928 62.08870764 66.70489964]\n",
      "[0.49139968 0.48215841 0.44653091]\n",
      "[0.24703223 0.24348513 0.26158784]\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./cifar10', train=True, download=True, transform=transform)\n",
    "\n",
    "print(trainset.data.shape)\n",
    "\n",
    "train_data_mean = trainset.data.mean(axis=(0,1,2))\n",
    "train_data_std = trainset.data.std(axis=(0,1,2))\n",
    "\n",
    "print(train_data_mean)\n",
    "print(train_data_std)\n",
    "\n",
    "train_data_mean = train_data_mean / 255\n",
    "train_data_std = train_data_std / 255\n",
    "\n",
    "print(train_data_mean)\n",
    "print(train_data_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(train_data_mean, train_data_std)\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(train_data_mean, train_data_std)\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./cifar10', train=True,\n",
    "                                        download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32,\n",
    "                                          shuffle=True, num_workers=0)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./cifar10', train=False,\n",
    "                                       download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32,\n",
    "                                         shuffle=False, num_workers=0)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make ResNet50 using resnet.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import resnet\n",
    "#import torchvision.models.resnet as resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1x1 = resnet.conv1x1\n",
    "Bottleneck = resnet.Bottleneck\n",
    "BasicBlock = resnet.BasicBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.inplanes = 16\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        #self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.layer1 = self._make_layer(block, 16, layers[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 32, layers[1], stride=1)\n",
    "        self.layer3 = self._make_layer(block, 64, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 128, layers[3], stride=2)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(128 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        #x.shape =[1, 16, 32,32]\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        #x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        #x.shape =[1, 128, 32,32]\n",
    "        x = self.layer2(x)\n",
    "        #x.shape =[1, 256, 32,32]\n",
    "        x = self.layer3(x)\n",
    "        #x.shape =[1, 512, 16,16]\n",
    "        x = self.layer4(x)\n",
    "        #x.shape =[1, 1024, 8,8]\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50 = ResNet(resnet.Bottleneck, [3, 4, 6, 3], 10, True).to(device)\n",
    "#1(conv1) + 9(layer1) + 12(layer2) + 18(layer3) + 9(layer4) +1(fc)= ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0138,  0.3299, -0.2943, -0.0283, -0.5507,  0.1456, -0.0667, -0.2085,\n",
      "         -0.0959,  0.0358]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "a = torch.Tensor(1, 3, 32, 32).to(device)\n",
    "out = resnet50(a)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.SGD(resnet50.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "lr_sche = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_plt = vis.line(Y=torch.Tensor(1).zero_(),opts=dict(title='loss_tracker', legend=['loss'], showlegend=True))\n",
    "acc_plt = vis.line(Y=torch.Tensor(1).zero_(),opts=dict(title='Accuracy', legend=['Acc'], showlegend=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define acc_check function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def acc_check(net, test_set, epoch, save=1):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_set:\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = net(images)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    acc = (100 * correct / total)\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % acc)\n",
    "    if save:\n",
    "        #torch.save(net.state_dict(), \"./model/model_epoch_{}_acc_{}.pth\".format(epoch, int(acc)))\n",
    "        model_dir = \"./model\"\n",
    "        os.makedirs(model_dir, exist_ok=True)  # 디렉토리가 없다면 생성합니다\n",
    "        model_path = os.path.join(model_dir, \"model_epoch_{}_acc_{}.pth\".format(epoch, int(acc)))\n",
    "        torch.save(net.state_dict(), model_path)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traning with (acc check + model save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563\n",
      "[1,    30] loss: 1.291\n",
      "[1,    60] loss: 1.308\n",
      "[1,    90] loss: 1.301\n",
      "[1,   120] loss: 1.230\n",
      "[1,   150] loss: 1.208\n",
      "[1,   180] loss: 1.303\n",
      "[1,   210] loss: 1.228\n",
      "[1,   240] loss: 1.162\n",
      "[1,   270] loss: 1.335\n",
      "[1,   300] loss: 1.214\n",
      "[1,   330] loss: 1.221\n",
      "[1,   360] loss: 1.246\n",
      "[1,   390] loss: 1.175\n",
      "[1,   420] loss: 1.235\n",
      "[1,   450] loss: 1.243\n",
      "[1,   480] loss: 1.243\n",
      "[1,   510] loss: 1.264\n",
      "[1,   540] loss: 1.215\n",
      "[1,   570] loss: 1.210\n",
      "[1,   600] loss: 1.228\n",
      "[1,   630] loss: 1.235\n",
      "[1,   660] loss: 1.165\n",
      "[1,   690] loss: 1.224\n",
      "[1,   720] loss: 1.194\n",
      "[1,   750] loss: 1.132\n",
      "[1,   780] loss: 1.209\n",
      "[1,   810] loss: 1.115\n",
      "[1,   840] loss: 1.150\n",
      "[1,   870] loss: 1.145\n",
      "[1,   900] loss: 1.132\n",
      "[1,   930] loss: 1.222\n",
      "[1,   960] loss: 1.128\n",
      "[1,   990] loss: 1.135\n",
      "[1,  1020] loss: 1.172\n",
      "[1,  1050] loss: 1.124\n",
      "[1,  1080] loss: 1.226\n",
      "[1,  1110] loss: 1.213\n",
      "[1,  1140] loss: 1.184\n",
      "[1,  1170] loss: 1.178\n",
      "[1,  1200] loss: 1.074\n",
      "[1,  1230] loss: 1.182\n",
      "[1,  1260] loss: 1.186\n",
      "[1,  1290] loss: 1.095\n",
      "[1,  1320] loss: 1.160\n",
      "[1,  1350] loss: 1.153\n",
      "[1,  1380] loss: 1.145\n",
      "[1,  1410] loss: 1.178\n",
      "[1,  1440] loss: 1.169\n",
      "[1,  1470] loss: 1.176\n",
      "[1,  1500] loss: 1.119\n",
      "[1,  1530] loss: 1.142\n",
      "[1,  1560] loss: 1.070\n",
      "Accuracy of the network on the 10000 test images: 54 %\n",
      "[2,    30] loss: 1.121\n",
      "[2,    60] loss: 1.064\n",
      "[2,    90] loss: 1.130\n",
      "[2,   120] loss: 1.203\n",
      "[2,   150] loss: 1.121\n",
      "[2,   180] loss: 1.081\n",
      "[2,   210] loss: 1.126\n",
      "[2,   240] loss: 1.115\n",
      "[2,   270] loss: 1.050\n",
      "[2,   300] loss: 1.146\n",
      "[2,   330] loss: 1.095\n",
      "[2,   360] loss: 1.060\n",
      "[2,   390] loss: 1.098\n",
      "[2,   420] loss: 1.118\n",
      "[2,   450] loss: 1.141\n",
      "[2,   480] loss: 1.106\n",
      "[2,   510] loss: 1.140\n",
      "[2,   540] loss: 1.047\n",
      "[2,   570] loss: 1.176\n",
      "[2,   600] loss: 1.143\n",
      "[2,   630] loss: 1.064\n",
      "[2,   660] loss: 1.083\n",
      "[2,   690] loss: 1.069\n",
      "[2,   720] loss: 1.141\n",
      "[2,   750] loss: 1.076\n",
      "[2,   780] loss: 1.032\n",
      "[2,   810] loss: 1.040\n",
      "[2,   840] loss: 1.163\n",
      "[2,   870] loss: 1.188\n",
      "[2,   900] loss: 1.084\n",
      "[2,   930] loss: 1.077\n",
      "[2,   960] loss: 1.125\n",
      "[2,   990] loss: 1.034\n",
      "[2,  1020] loss: 1.031\n",
      "[2,  1050] loss: 1.097\n",
      "[2,  1080] loss: 1.134\n",
      "[2,  1110] loss: 1.148\n",
      "[2,  1140] loss: 1.105\n",
      "[2,  1170] loss: 1.115\n",
      "[2,  1200] loss: 1.063\n",
      "[2,  1230] loss: 1.062\n",
      "[2,  1260] loss: 0.995\n",
      "[2,  1290] loss: 1.098\n",
      "[2,  1320] loss: 1.092\n",
      "[2,  1350] loss: 1.122\n",
      "[2,  1380] loss: 1.084\n",
      "[2,  1410] loss: 0.988\n",
      "[2,  1440] loss: 1.075\n",
      "[2,  1470] loss: 1.044\n",
      "[2,  1500] loss: 1.090\n",
      "[2,  1530] loss: 1.055\n",
      "[2,  1560] loss: 0.999\n",
      "Accuracy of the network on the 10000 test images: 54 %\n",
      "[3,    30] loss: 1.064\n",
      "[3,    60] loss: 0.996\n",
      "[3,    90] loss: 1.071\n",
      "[3,   120] loss: 1.034\n",
      "[3,   150] loss: 1.067\n",
      "[3,   180] loss: 1.151\n",
      "[3,   210] loss: 1.040\n",
      "[3,   240] loss: 1.058\n",
      "[3,   270] loss: 1.080\n",
      "[3,   300] loss: 1.060\n",
      "[3,   330] loss: 1.030\n",
      "[3,   360] loss: 1.099\n",
      "[3,   390] loss: 1.048\n",
      "[3,   420] loss: 1.020\n",
      "[3,   450] loss: 1.038\n",
      "[3,   480] loss: 1.072\n",
      "[3,   510] loss: 1.046\n",
      "[3,   540] loss: 1.078\n",
      "[3,   570] loss: 1.008\n",
      "[3,   600] loss: 1.037\n",
      "[3,   630] loss: 1.042\n",
      "[3,   660] loss: 1.036\n",
      "[3,   690] loss: 1.033\n",
      "[3,   720] loss: 1.016\n",
      "[3,   750] loss: 0.963\n",
      "[3,   780] loss: 1.061\n",
      "[3,   810] loss: 1.021\n",
      "[3,   840] loss: 1.031\n",
      "[3,   870] loss: 1.073\n",
      "[3,   900] loss: 1.020\n",
      "[3,   930] loss: 1.045\n",
      "[3,   960] loss: 1.060\n",
      "[3,   990] loss: 0.979\n",
      "[3,  1020] loss: 1.029\n",
      "[3,  1050] loss: 1.056\n",
      "[3,  1080] loss: 1.009\n",
      "[3,  1110] loss: 0.984\n",
      "[3,  1140] loss: 0.999\n",
      "[3,  1170] loss: 1.106\n",
      "[3,  1200] loss: 1.038\n",
      "[3,  1230] loss: 1.026\n",
      "[3,  1260] loss: 1.042\n",
      "[3,  1290] loss: 1.057\n",
      "[3,  1320] loss: 1.021\n",
      "[3,  1350] loss: 1.012\n",
      "[3,  1380] loss: 1.097\n",
      "[3,  1410] loss: 0.974\n",
      "[3,  1440] loss: 1.074\n",
      "[3,  1470] loss: 1.102\n",
      "[3,  1500] loss: 1.035\n",
      "[3,  1530] loss: 0.961\n",
      "[3,  1560] loss: 1.001\n",
      "Accuracy of the network on the 10000 test images: 59 %\n",
      "[4,    30] loss: 1.057\n",
      "[4,    60] loss: 0.998\n",
      "[4,    90] loss: 0.919\n",
      "[4,   120] loss: 1.021\n",
      "[4,   150] loss: 0.959\n",
      "[4,   180] loss: 0.983\n",
      "[4,   210] loss: 1.093\n",
      "[4,   240] loss: 1.012\n",
      "[4,   270] loss: 1.024\n",
      "[4,   300] loss: 1.031\n",
      "[4,   330] loss: 0.973\n",
      "[4,   360] loss: 0.973\n",
      "[4,   390] loss: 1.009\n",
      "[4,   420] loss: 1.054\n",
      "[4,   450] loss: 1.094\n",
      "[4,   480] loss: 1.019\n",
      "[4,   510] loss: 1.010\n",
      "[4,   540] loss: 1.015\n",
      "[4,   570] loss: 1.028\n",
      "[4,   600] loss: 1.012\n",
      "[4,   630] loss: 1.002\n",
      "[4,   660] loss: 1.008\n",
      "[4,   690] loss: 0.981\n",
      "[4,   720] loss: 1.015\n",
      "[4,   750] loss: 1.053\n",
      "[4,   780] loss: 0.960\n",
      "[4,   810] loss: 0.972\n",
      "[4,   840] loss: 1.028\n",
      "[4,   870] loss: 0.985\n",
      "[4,   900] loss: 0.988\n",
      "[4,   930] loss: 0.868\n",
      "[4,   960] loss: 0.940\n",
      "[4,   990] loss: 1.084\n",
      "[4,  1020] loss: 1.066\n",
      "[4,  1050] loss: 1.017\n",
      "[4,  1080] loss: 0.999\n",
      "[4,  1110] loss: 0.976\n",
      "[4,  1140] loss: 0.939\n",
      "[4,  1170] loss: 0.933\n",
      "[4,  1200] loss: 1.002\n",
      "[4,  1230] loss: 0.934\n",
      "[4,  1260] loss: 0.979\n",
      "[4,  1290] loss: 0.979\n",
      "[4,  1320] loss: 0.980\n",
      "[4,  1350] loss: 0.962\n",
      "[4,  1380] loss: 0.977\n",
      "[4,  1410] loss: 0.947\n",
      "[4,  1440] loss: 0.968\n",
      "[4,  1470] loss: 0.960\n",
      "[4,  1500] loss: 0.995\n",
      "[4,  1530] loss: 0.966\n",
      "[4,  1560] loss: 1.101\n",
      "Accuracy of the network on the 10000 test images: 61 %\n",
      "[5,    30] loss: 0.966\n",
      "[5,    60] loss: 0.951\n",
      "[5,    90] loss: 0.941\n",
      "[5,   120] loss: 0.897\n",
      "[5,   150] loss: 0.929\n",
      "[5,   180] loss: 0.936\n",
      "[5,   210] loss: 0.887\n",
      "[5,   240] loss: 0.937\n",
      "[5,   270] loss: 1.011\n",
      "[5,   300] loss: 0.942\n",
      "[5,   330] loss: 0.925\n",
      "[5,   360] loss: 0.961\n",
      "[5,   390] loss: 1.005\n",
      "[5,   420] loss: 0.897\n",
      "[5,   450] loss: 0.955\n",
      "[5,   480] loss: 0.931\n",
      "[5,   510] loss: 0.975\n",
      "[5,   540] loss: 1.037\n",
      "[5,   570] loss: 0.973\n",
      "[5,   600] loss: 0.924\n",
      "[5,   630] loss: 1.045\n",
      "[5,   660] loss: 0.927\n",
      "[5,   690] loss: 0.999\n",
      "[5,   720] loss: 0.980\n",
      "[5,   750] loss: 0.899\n",
      "[5,   780] loss: 0.992\n",
      "[5,   810] loss: 0.940\n",
      "[5,   840] loss: 0.919\n",
      "[5,   870] loss: 0.989\n",
      "[5,   900] loss: 0.857\n",
      "[5,   930] loss: 0.918\n",
      "[5,   960] loss: 0.952\n",
      "[5,   990] loss: 0.877\n",
      "[5,  1020] loss: 0.987\n",
      "[5,  1050] loss: 0.994\n",
      "[5,  1080] loss: 0.904\n",
      "[5,  1110] loss: 0.952\n",
      "[5,  1140] loss: 1.005\n",
      "[5,  1170] loss: 0.979\n",
      "[5,  1200] loss: 0.905\n",
      "[5,  1230] loss: 0.946\n",
      "[5,  1260] loss: 0.984\n",
      "[5,  1290] loss: 0.907\n",
      "[5,  1320] loss: 0.855\n",
      "[5,  1350] loss: 0.920\n",
      "[5,  1380] loss: 0.932\n",
      "[5,  1410] loss: 0.954\n",
      "[5,  1440] loss: 0.985\n",
      "[5,  1470] loss: 0.969\n",
      "[5,  1500] loss: 0.939\n",
      "[5,  1530] loss: 0.952\n",
      "[5,  1560] loss: 0.924\n",
      "Accuracy of the network on the 10000 test images: 64 %\n",
      "[6,    30] loss: 0.890\n",
      "[6,    60] loss: 0.932\n",
      "[6,    90] loss: 0.860\n",
      "[6,   120] loss: 0.980\n",
      "[6,   150] loss: 0.877\n",
      "[6,   180] loss: 0.933\n",
      "[6,   210] loss: 0.895\n",
      "[6,   240] loss: 1.007\n",
      "[6,   270] loss: 0.936\n",
      "[6,   300] loss: 0.947\n",
      "[6,   330] loss: 0.909\n",
      "[6,   360] loss: 0.876\n",
      "[6,   390] loss: 0.884\n",
      "[6,   420] loss: 0.912\n",
      "[6,   450] loss: 0.882\n",
      "[6,   480] loss: 0.952\n",
      "[6,   510] loss: 0.913\n",
      "[6,   540] loss: 0.917\n",
      "[6,   570] loss: 0.962\n",
      "[6,   600] loss: 0.953\n",
      "[6,   630] loss: 0.922\n",
      "[6,   660] loss: 0.877\n",
      "[6,   690] loss: 0.854\n",
      "[6,   720] loss: 0.824\n",
      "[6,   750] loss: 0.841\n",
      "[6,   780] loss: 0.954\n",
      "[6,   810] loss: 0.924\n",
      "[6,   840] loss: 0.882\n",
      "[6,   870] loss: 0.914\n",
      "[6,   900] loss: 0.962\n",
      "[6,   930] loss: 0.935\n",
      "[6,   960] loss: 0.915\n",
      "[6,   990] loss: 0.854\n",
      "[6,  1020] loss: 0.928\n",
      "[6,  1050] loss: 0.897\n",
      "[6,  1080] loss: 0.792\n",
      "[6,  1110] loss: 0.962\n",
      "[6,  1140] loss: 1.011\n",
      "[6,  1170] loss: 0.910\n",
      "[6,  1200] loss: 0.832\n",
      "[6,  1230] loss: 0.864\n",
      "[6,  1260] loss: 0.861\n",
      "[6,  1290] loss: 0.947\n",
      "[6,  1320] loss: 0.886\n",
      "[6,  1350] loss: 0.891\n",
      "[6,  1380] loss: 0.900\n",
      "[6,  1410] loss: 0.890\n",
      "[6,  1440] loss: 0.911\n",
      "[6,  1470] loss: 0.950\n",
      "[6,  1500] loss: 0.938\n",
      "[6,  1530] loss: 0.998\n",
      "[6,  1560] loss: 0.829\n",
      "Accuracy of the network on the 10000 test images: 64 %\n",
      "[7,    30] loss: 0.977\n",
      "[7,    60] loss: 0.909\n",
      "[7,    90] loss: 0.923\n",
      "[7,   120] loss: 0.882\n",
      "[7,   150] loss: 0.858\n",
      "[7,   180] loss: 0.904\n",
      "[7,   210] loss: 0.818\n",
      "[7,   240] loss: 0.937\n",
      "[7,   270] loss: 0.928\n",
      "[7,   300] loss: 0.896\n",
      "[7,   330] loss: 0.883\n",
      "[7,   360] loss: 0.896\n",
      "[7,   390] loss: 0.893\n",
      "[7,   420] loss: 0.907\n",
      "[7,   450] loss: 0.819\n",
      "[7,   480] loss: 0.832\n",
      "[7,   510] loss: 0.887\n",
      "[7,   540] loss: 0.943\n",
      "[7,   570] loss: 0.891\n",
      "[7,   600] loss: 0.997\n",
      "[7,   630] loss: 0.868\n",
      "[7,   660] loss: 0.867\n",
      "[7,   690] loss: 0.854\n",
      "[7,   720] loss: 0.897\n",
      "[7,   750] loss: 0.856\n",
      "[7,   780] loss: 0.936\n",
      "[7,   810] loss: 0.883\n",
      "[7,   840] loss: 0.961\n",
      "[7,   870] loss: 0.855\n",
      "[7,   900] loss: 0.874\n",
      "[7,   930] loss: 0.840\n",
      "[7,   960] loss: 0.891\n",
      "[7,   990] loss: 0.857\n",
      "[7,  1020] loss: 0.931\n",
      "[7,  1050] loss: 0.872\n",
      "[7,  1080] loss: 0.811\n",
      "[7,  1110] loss: 0.826\n",
      "[7,  1140] loss: 0.869\n",
      "[7,  1170] loss: 0.815\n",
      "[7,  1200] loss: 0.827\n",
      "[7,  1230] loss: 0.959\n",
      "[7,  1260] loss: 0.876\n",
      "[7,  1290] loss: 0.899\n",
      "[7,  1320] loss: 0.881\n",
      "[7,  1350] loss: 0.904\n",
      "[7,  1380] loss: 0.857\n",
      "[7,  1410] loss: 0.857\n",
      "[7,  1440] loss: 0.969\n",
      "[7,  1470] loss: 0.863\n",
      "[7,  1500] loss: 0.810\n",
      "[7,  1530] loss: 0.818\n",
      "[7,  1560] loss: 0.825\n",
      "Accuracy of the network on the 10000 test images: 66 %\n",
      "[8,    30] loss: 0.831\n",
      "[8,    60] loss: 0.849\n",
      "[8,    90] loss: 0.878\n",
      "[8,   120] loss: 0.883\n",
      "[8,   150] loss: 0.779\n",
      "[8,   180] loss: 0.883\n",
      "[8,   210] loss: 0.912\n",
      "[8,   240] loss: 0.892\n",
      "[8,   270] loss: 0.779\n",
      "[8,   300] loss: 0.870\n",
      "[8,   330] loss: 0.883\n",
      "[8,   360] loss: 0.906\n",
      "[8,   390] loss: 0.852\n",
      "[8,   420] loss: 0.828\n",
      "[8,   450] loss: 0.873\n",
      "[8,   480] loss: 0.932\n",
      "[8,   510] loss: 0.912\n",
      "[8,   540] loss: 0.833\n",
      "[8,   570] loss: 0.837\n",
      "[8,   600] loss: 0.889\n",
      "[8,   630] loss: 0.851\n",
      "[8,   660] loss: 0.892\n",
      "[8,   690] loss: 0.877\n",
      "[8,   720] loss: 0.865\n",
      "[8,   750] loss: 0.895\n",
      "[8,   780] loss: 0.842\n",
      "[8,   810] loss: 0.882\n",
      "[8,   840] loss: 0.851\n",
      "[8,   870] loss: 0.923\n",
      "[8,   900] loss: 0.856\n",
      "[8,   930] loss: 0.881\n",
      "[8,   960] loss: 0.875\n",
      "[8,   990] loss: 0.884\n",
      "[8,  1020] loss: 0.808\n",
      "[8,  1050] loss: 0.864\n",
      "[8,  1080] loss: 0.888\n",
      "[8,  1110] loss: 0.888\n",
      "[8,  1140] loss: 0.822\n",
      "[8,  1170] loss: 0.755\n",
      "[8,  1200] loss: 0.904\n",
      "[8,  1230] loss: 0.874\n",
      "[8,  1260] loss: 0.857\n",
      "[8,  1290] loss: 0.856\n",
      "[8,  1320] loss: 0.840\n",
      "[8,  1350] loss: 0.780\n",
      "[8,  1380] loss: 0.857\n",
      "[8,  1410] loss: 0.978\n",
      "[8,  1440] loss: 0.880\n",
      "[8,  1470] loss: 0.874\n",
      "[8,  1500] loss: 0.890\n",
      "[8,  1530] loss: 0.863\n",
      "[8,  1560] loss: 0.885\n",
      "Accuracy of the network on the 10000 test images: 64 %\n",
      "[9,    30] loss: 0.736\n",
      "[9,    60] loss: 0.744\n",
      "[9,    90] loss: 0.650\n",
      "[9,   120] loss: 0.701\n",
      "[9,   150] loss: 0.691\n",
      "[9,   180] loss: 0.708\n",
      "[9,   210] loss: 0.681\n",
      "[9,   240] loss: 0.742\n",
      "[9,   270] loss: 0.669\n",
      "[9,   300] loss: 0.658\n",
      "[9,   330] loss: 0.745\n",
      "[9,   360] loss: 0.737\n",
      "[9,   390] loss: 0.637\n",
      "[9,   420] loss: 0.655\n",
      "[9,   450] loss: 0.707\n",
      "[9,   480] loss: 0.624\n",
      "[9,   510] loss: 0.686\n",
      "[9,   540] loss: 0.699\n",
      "[9,   570] loss: 0.728\n",
      "[9,   600] loss: 0.707\n",
      "[9,   630] loss: 0.725\n",
      "[9,   660] loss: 0.730\n",
      "[9,   690] loss: 0.694\n",
      "[9,   720] loss: 0.715\n",
      "[9,   750] loss: 0.682\n",
      "[9,   780] loss: 0.661\n",
      "[9,   810] loss: 0.670\n",
      "[9,   840] loss: 0.650\n",
      "[9,   870] loss: 0.737\n",
      "[9,   900] loss: 0.697\n",
      "[9,   930] loss: 0.706\n",
      "[9,   960] loss: 0.740\n",
      "[9,   990] loss: 0.592\n",
      "[9,  1020] loss: 0.676\n",
      "[9,  1050] loss: 0.700\n",
      "[9,  1080] loss: 0.743\n",
      "[9,  1110] loss: 0.680\n",
      "[9,  1140] loss: 0.639\n",
      "[9,  1170] loss: 0.680\n",
      "[9,  1200] loss: 0.698\n",
      "[9,  1230] loss: 0.748\n",
      "[9,  1260] loss: 0.711\n",
      "[9,  1290] loss: 0.675\n",
      "[9,  1320] loss: 0.719\n",
      "[9,  1350] loss: 0.693\n",
      "[9,  1380] loss: 0.671\n",
      "[9,  1410] loss: 0.747\n",
      "[9,  1440] loss: 0.634\n",
      "[9,  1470] loss: 0.685\n",
      "[9,  1500] loss: 0.699\n",
      "[9,  1530] loss: 0.731\n",
      "[9,  1560] loss: 0.699\n",
      "Accuracy of the network on the 10000 test images: 71 %\n",
      "[10,    30] loss: 0.697\n",
      "[10,    60] loss: 0.658\n",
      "[10,    90] loss: 0.671\n",
      "[10,   120] loss: 0.670\n",
      "[10,   150] loss: 0.694\n",
      "[10,   180] loss: 0.704\n",
      "[10,   210] loss: 0.662\n",
      "[10,   240] loss: 0.688\n",
      "[10,   270] loss: 0.662\n",
      "[10,   300] loss: 0.674\n",
      "[10,   330] loss: 0.645\n",
      "[10,   360] loss: 0.700\n",
      "[10,   390] loss: 0.741\n",
      "[10,   420] loss: 0.822\n",
      "[10,   450] loss: 0.768\n",
      "[10,   480] loss: 0.734\n",
      "[10,   510] loss: 0.676\n",
      "[10,   540] loss: 0.624\n",
      "[10,   570] loss: 0.675\n",
      "[10,   600] loss: 0.689\n",
      "[10,   630] loss: 0.731\n",
      "[10,   660] loss: 0.711\n",
      "[10,   690] loss: 0.732\n",
      "[10,   720] loss: 0.770\n",
      "[10,   750] loss: 0.708\n",
      "[10,   780] loss: 0.665\n",
      "[10,   810] loss: 0.648\n",
      "[10,   840] loss: 0.734\n",
      "[10,   870] loss: 0.728\n",
      "[10,   900] loss: 0.669\n",
      "[10,   930] loss: 0.688\n",
      "[10,   960] loss: 0.728\n",
      "[10,   990] loss: 0.785\n",
      "[10,  1020] loss: 0.769\n",
      "[10,  1050] loss: 0.736\n",
      "[10,  1080] loss: 0.674\n",
      "[10,  1110] loss: 0.636\n",
      "[10,  1140] loss: 0.642\n",
      "[10,  1170] loss: 0.684\n",
      "[10,  1200] loss: 0.713\n",
      "[10,  1230] loss: 0.755\n",
      "[10,  1260] loss: 0.728\n",
      "[10,  1290] loss: 0.633\n",
      "[10,  1320] loss: 0.669\n",
      "[10,  1350] loss: 0.699\n",
      "[10,  1380] loss: 0.723\n",
      "[10,  1410] loss: 0.764\n",
      "[10,  1440] loss: 0.670\n",
      "[10,  1470] loss: 0.620\n",
      "[10,  1500] loss: 0.716\n",
      "[10,  1530] loss: 0.701\n",
      "[10,  1560] loss: 0.759\n",
      "Accuracy of the network on the 10000 test images: 69 %\n",
      "[11,    30] loss: 0.783\n",
      "[11,    60] loss: 0.656\n",
      "[11,    90] loss: 0.633\n",
      "[11,   120] loss: 0.647\n",
      "[11,   150] loss: 0.618\n",
      "[11,   180] loss: 0.642\n",
      "[11,   210] loss: 0.693\n",
      "[11,   240] loss: 0.669\n",
      "[11,   270] loss: 0.636\n",
      "[11,   300] loss: 0.612\n",
      "[11,   330] loss: 0.682\n",
      "[11,   360] loss: 0.759\n",
      "[11,   390] loss: 0.729\n",
      "[11,   420] loss: 0.668\n",
      "[11,   450] loss: 0.675\n",
      "[11,   480] loss: 0.711\n",
      "[11,   510] loss: 0.726\n",
      "[11,   540] loss: 0.741\n",
      "[11,   570] loss: 0.661\n",
      "[11,   600] loss: 0.701\n",
      "[11,   630] loss: 0.632\n",
      "[11,   660] loss: 0.723\n",
      "[11,   690] loss: 0.733\n",
      "[11,   720] loss: 0.652\n",
      "[11,   750] loss: 0.662\n",
      "[11,   780] loss: 0.716\n",
      "[11,   810] loss: 0.678\n",
      "[11,   840] loss: 0.699\n",
      "[11,   870] loss: 0.677\n",
      "[11,   900] loss: 0.687\n",
      "[11,   930] loss: 0.713\n",
      "[11,   960] loss: 0.717\n",
      "[11,   990] loss: 0.647\n",
      "[11,  1020] loss: 0.696\n",
      "[11,  1050] loss: 0.755\n",
      "[11,  1080] loss: 0.605\n",
      "[11,  1110] loss: 0.644\n",
      "[11,  1140] loss: 0.749\n",
      "[11,  1170] loss: 0.761\n",
      "[11,  1200] loss: 0.625\n",
      "[11,  1230] loss: 0.604\n",
      "[11,  1260] loss: 0.713\n",
      "[11,  1290] loss: 0.709\n",
      "[11,  1320] loss: 0.623\n",
      "[11,  1350] loss: 0.673\n",
      "[11,  1380] loss: 0.729\n",
      "[11,  1410] loss: 0.721\n",
      "[11,  1440] loss: 0.696\n",
      "[11,  1470] loss: 0.665\n",
      "[11,  1500] loss: 0.665\n",
      "[11,  1530] loss: 0.728\n",
      "[11,  1560] loss: 0.698\n",
      "Accuracy of the network on the 10000 test images: 70 %\n",
      "[12,    30] loss: 0.720\n",
      "[12,    60] loss: 0.656\n",
      "[12,    90] loss: 0.689\n",
      "[12,   120] loss: 0.646\n",
      "[12,   150] loss: 0.636\n",
      "[12,   180] loss: 0.642\n",
      "[12,   210] loss: 0.651\n",
      "[12,   240] loss: 0.697\n",
      "[12,   270] loss: 0.637\n",
      "[12,   300] loss: 0.715\n",
      "[12,   330] loss: 0.626\n",
      "[12,   360] loss: 0.658\n",
      "[12,   390] loss: 0.702\n",
      "[12,   420] loss: 0.644\n",
      "[12,   450] loss: 0.695\n",
      "[12,   480] loss: 0.665\n",
      "[12,   510] loss: 0.661\n",
      "[12,   540] loss: 0.665\n",
      "[12,   570] loss: 0.687\n",
      "[12,   600] loss: 0.631\n",
      "[12,   630] loss: 0.708\n",
      "[12,   660] loss: 0.679\n",
      "[12,   690] loss: 0.649\n",
      "[12,   720] loss: 0.705\n",
      "[12,   750] loss: 0.665\n",
      "[12,   780] loss: 0.702\n",
      "[12,   810] loss: 0.705\n",
      "[12,   840] loss: 0.678\n",
      "[12,   870] loss: 0.612\n",
      "[12,   900] loss: 0.664\n",
      "[12,   930] loss: 0.683\n",
      "[12,   960] loss: 0.747\n",
      "[12,   990] loss: 0.771\n",
      "[12,  1020] loss: 0.710\n",
      "[12,  1050] loss: 0.658\n",
      "[12,  1080] loss: 0.674\n",
      "[12,  1110] loss: 0.713\n",
      "[12,  1140] loss: 0.628\n",
      "[12,  1170] loss: 0.631\n",
      "[12,  1200] loss: 0.669\n",
      "[12,  1230] loss: 0.677\n",
      "[12,  1260] loss: 0.722\n",
      "[12,  1290] loss: 0.652\n",
      "[12,  1320] loss: 0.631\n",
      "[12,  1350] loss: 0.709\n",
      "[12,  1380] loss: 0.635\n",
      "[12,  1410] loss: 0.725\n",
      "[12,  1440] loss: 0.700\n",
      "[12,  1470] loss: 0.675\n",
      "[12,  1500] loss: 0.652\n",
      "[12,  1530] loss: 0.654\n",
      "[12,  1560] loss: 0.674\n",
      "Accuracy of the network on the 10000 test images: 72 %\n",
      "[13,    30] loss: 0.627\n",
      "[13,    60] loss: 0.693\n",
      "[13,    90] loss: 0.638\n",
      "[13,   120] loss: 0.649\n",
      "[13,   150] loss: 0.762\n",
      "[13,   180] loss: 0.654\n",
      "[13,   210] loss: 0.653\n",
      "[13,   240] loss: 0.646\n",
      "[13,   270] loss: 0.658\n",
      "[13,   300] loss: 0.630\n",
      "[13,   330] loss: 0.654\n",
      "[13,   360] loss: 0.707\n",
      "[13,   390] loss: 0.638\n",
      "[13,   420] loss: 0.632\n",
      "[13,   450] loss: 0.628\n",
      "[13,   480] loss: 0.646\n",
      "[13,   510] loss: 0.666\n",
      "[13,   540] loss: 0.687\n",
      "[13,   570] loss: 0.678\n",
      "[13,   600] loss: 0.655\n",
      "[13,   630] loss: 0.613\n",
      "[13,   660] loss: 0.685\n",
      "[13,   690] loss: 0.668\n",
      "[13,   720] loss: 0.738\n",
      "[13,   750] loss: 0.686\n",
      "[13,   780] loss: 0.715\n",
      "[13,   810] loss: 0.677\n",
      "[13,   840] loss: 0.636\n",
      "[13,   870] loss: 0.644\n",
      "[13,   900] loss: 0.666\n",
      "[13,   930] loss: 0.679\n",
      "[13,   960] loss: 0.731\n",
      "[13,   990] loss: 0.689\n",
      "[13,  1020] loss: 0.717\n",
      "[13,  1050] loss: 0.717\n",
      "[13,  1080] loss: 0.694\n",
      "[13,  1110] loss: 0.717\n",
      "[13,  1140] loss: 0.655\n",
      "[13,  1170] loss: 0.684\n",
      "[13,  1200] loss: 0.636\n",
      "[13,  1230] loss: 0.668\n",
      "[13,  1260] loss: 0.701\n",
      "[13,  1290] loss: 0.705\n",
      "[13,  1320] loss: 0.724\n",
      "[13,  1350] loss: 0.633\n",
      "[13,  1380] loss: 0.666\n",
      "[13,  1410] loss: 0.616\n",
      "[13,  1440] loss: 0.648\n",
      "[13,  1470] loss: 0.615\n",
      "[13,  1500] loss: 0.697\n",
      "[13,  1530] loss: 0.649\n",
      "[13,  1560] loss: 0.687\n",
      "Accuracy of the network on the 10000 test images: 70 %\n",
      "[14,    30] loss: 0.655\n",
      "[14,    60] loss: 0.614\n",
      "[14,    90] loss: 0.597\n",
      "[14,   120] loss: 0.625\n",
      "[14,   150] loss: 0.597\n",
      "[14,   180] loss: 0.604\n",
      "[14,   210] loss: 0.644\n",
      "[14,   240] loss: 0.665\n",
      "[14,   270] loss: 0.652\n",
      "[14,   300] loss: 0.687\n",
      "[14,   330] loss: 0.690\n",
      "[14,   360] loss: 0.661\n",
      "[14,   390] loss: 0.714\n",
      "[14,   420] loss: 0.621\n",
      "[14,   450] loss: 0.602\n",
      "[14,   480] loss: 0.640\n",
      "[14,   510] loss: 0.667\n",
      "[14,   540] loss: 0.630\n",
      "[14,   570] loss: 0.715\n",
      "[14,   600] loss: 0.637\n",
      "[14,   630] loss: 0.635\n",
      "[14,   660] loss: 0.664\n",
      "[14,   690] loss: 0.622\n",
      "[14,   720] loss: 0.666\n",
      "[14,   750] loss: 0.648\n",
      "[14,   780] loss: 0.622\n",
      "[14,   810] loss: 0.679\n",
      "[14,   840] loss: 0.698\n",
      "[14,   870] loss: 0.685\n",
      "[14,   900] loss: 0.613\n",
      "[14,   930] loss: 0.655\n",
      "[14,   960] loss: 0.666\n",
      "[14,   990] loss: 0.632\n",
      "[14,  1020] loss: 0.687\n",
      "[14,  1050] loss: 0.677\n",
      "[14,  1080] loss: 0.698\n",
      "[14,  1110] loss: 0.668\n",
      "[14,  1140] loss: 0.672\n",
      "[14,  1170] loss: 0.665\n",
      "[14,  1200] loss: 0.676\n",
      "[14,  1230] loss: 0.679\n",
      "[14,  1260] loss: 0.674\n",
      "[14,  1290] loss: 0.601\n",
      "[14,  1320] loss: 0.642\n",
      "[14,  1350] loss: 0.614\n",
      "[14,  1380] loss: 0.694\n",
      "[14,  1410] loss: 0.664\n",
      "[14,  1440] loss: 0.689\n",
      "[14,  1470] loss: 0.706\n",
      "[14,  1500] loss: 0.612\n",
      "[14,  1530] loss: 0.674\n",
      "[14,  1560] loss: 0.676\n",
      "Accuracy of the network on the 10000 test images: 73 %\n",
      "[15,    30] loss: 0.623\n",
      "[15,    60] loss: 0.668\n",
      "[15,    90] loss: 0.594\n",
      "[15,   120] loss: 0.686\n",
      "[15,   150] loss: 0.679\n",
      "[15,   180] loss: 0.642\n",
      "[15,   210] loss: 0.568\n",
      "[15,   240] loss: 0.609\n",
      "[15,   270] loss: 0.620\n",
      "[15,   300] loss: 0.614\n",
      "[15,   330] loss: 0.635\n",
      "[15,   360] loss: 0.671\n",
      "[15,   390] loss: 0.654\n",
      "[15,   420] loss: 0.669\n",
      "[15,   450] loss: 0.647\n",
      "[15,   480] loss: 0.663\n",
      "[15,   510] loss: 0.726\n",
      "[15,   540] loss: 0.686\n",
      "[15,   570] loss: 0.621\n",
      "[15,   600] loss: 0.676\n",
      "[15,   630] loss: 0.648\n",
      "[15,   660] loss: 0.662\n",
      "[15,   690] loss: 0.686\n",
      "[15,   720] loss: 0.676\n",
      "[15,   750] loss: 0.681\n",
      "[15,   780] loss: 0.680\n",
      "[15,   810] loss: 0.602\n",
      "[15,   840] loss: 0.638\n",
      "[15,   870] loss: 0.672\n",
      "[15,   900] loss: 0.595\n",
      "[15,   930] loss: 0.651\n",
      "[15,   960] loss: 0.627\n",
      "[15,   990] loss: 0.620\n",
      "[15,  1020] loss: 0.638\n",
      "[15,  1050] loss: 0.688\n",
      "[15,  1080] loss: 0.650\n",
      "[15,  1110] loss: 0.624\n",
      "[15,  1140] loss: 0.694\n",
      "[15,  1170] loss: 0.650\n",
      "[15,  1200] loss: 0.672\n",
      "[15,  1230] loss: 0.645\n",
      "[15,  1260] loss: 0.694\n",
      "[15,  1290] loss: 0.653\n",
      "[15,  1320] loss: 0.647\n",
      "[15,  1350] loss: 0.569\n",
      "[15,  1380] loss: 0.682\n",
      "[15,  1410] loss: 0.687\n",
      "[15,  1440] loss: 0.674\n",
      "[15,  1470] loss: 0.665\n",
      "[15,  1500] loss: 0.647\n",
      "[15,  1530] loss: 0.648\n",
      "[15,  1560] loss: 0.639\n",
      "Accuracy of the network on the 10000 test images: 73 %\n",
      "[16,    30] loss: 0.598\n",
      "[16,    60] loss: 0.671\n",
      "[16,    90] loss: 0.591\n",
      "[16,   120] loss: 0.619\n",
      "[16,   150] loss: 0.632\n",
      "[16,   180] loss: 0.640\n",
      "[16,   210] loss: 0.635\n",
      "[16,   240] loss: 0.578\n",
      "[16,   270] loss: 0.642\n",
      "[16,   300] loss: 0.596\n",
      "[16,   330] loss: 0.690\n",
      "[16,   360] loss: 0.615\n",
      "[16,   390] loss: 0.647\n",
      "[16,   420] loss: 0.581\n",
      "[16,   450] loss: 0.673\n",
      "[16,   480] loss: 0.656\n",
      "[16,   510] loss: 0.662\n",
      "[16,   540] loss: 0.663\n",
      "[16,   570] loss: 0.612\n",
      "[16,   600] loss: 0.627\n",
      "[16,   630] loss: 0.599\n",
      "[16,   660] loss: 0.631\n",
      "[16,   690] loss: 0.651\n",
      "[16,   720] loss: 0.639\n",
      "[16,   750] loss: 0.641\n",
      "[16,   780] loss: 0.670\n",
      "[16,   810] loss: 0.650\n",
      "[16,   840] loss: 0.680\n",
      "[16,   870] loss: 0.714\n",
      "[16,   900] loss: 0.606\n",
      "[16,   930] loss: 0.701\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m running_loss \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[0;32m     11\u001b[0m lr_sche\u001b[39m.\u001b[39mstep()\n\u001b[1;32m---> 12\u001b[0m \u001b[39mfor\u001b[39;00m i, data \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(trainloader, \u001b[39m0\u001b[39m):\n\u001b[0;32m     13\u001b[0m     \u001b[39m# get the inputs\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     inputs, labels \u001b[39m=\u001b[39m data\n\u001b[0;32m     15\u001b[0m     inputs \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[1;32mc:\\Users\\jys74\\anaconda3\\envs\\PyTorch\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\jys74\\anaconda3\\envs\\PyTorch\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    676\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    677\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 678\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    679\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    680\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\jys74\\anaconda3\\envs\\PyTorch\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;49;00m idx \u001b[39min\u001b[39;49;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\jys74\\anaconda3\\envs\\PyTorch\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\jys74\\anaconda3\\envs\\PyTorch\\Lib\\site-packages\\torchvision\\datasets\\cifar.py:118\u001b[0m, in \u001b[0;36mCIFAR10.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    115\u001b[0m img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mfromarray(img)\n\u001b[0;32m    117\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 118\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(img)\n\u001b[0;32m    120\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    121\u001b[0m     target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[1;32mc:\\Users\\jys74\\anaconda3\\envs\\PyTorch\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[39m=\u001b[39m t(img)\n\u001b[0;32m     96\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
      "File \u001b[1;32mc:\\Users\\jys74\\anaconda3\\envs\\PyTorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\jys74\\anaconda3\\envs\\PyTorch\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:688\u001b[0m, in \u001b[0;36mRandomCrop.forward\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m    685\u001b[0m     padding \u001b[39m=\u001b[39m [\u001b[39m0\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msize[\u001b[39m0\u001b[39m] \u001b[39m-\u001b[39m height]\n\u001b[0;32m    686\u001b[0m     img \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mpad(img, padding, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfill, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode)\n\u001b[1;32m--> 688\u001b[0m i, j, h, w \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_params(img, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msize)\n\u001b[0;32m    690\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mcrop(img, i, j, h, w)\n",
      "File \u001b[1;32mc:\\Users\\jys74\\anaconda3\\envs\\PyTorch\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:652\u001b[0m, in \u001b[0;36mRandomCrop.get_params\u001b[1;34m(img, output_size)\u001b[0m\n\u001b[0;32m    649\u001b[0m \u001b[39mif\u001b[39;00m w \u001b[39m==\u001b[39m tw \u001b[39mand\u001b[39;00m h \u001b[39m==\u001b[39m th:\n\u001b[0;32m    650\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, h, w\n\u001b[1;32m--> 652\u001b[0m i \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mrandint(\u001b[39m0\u001b[39;49m, h \u001b[39m-\u001b[39;49m th \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m, size\u001b[39m=\u001b[39;49m(\u001b[39m1\u001b[39;49m,))\u001b[39m.\u001b[39mitem()\n\u001b[0;32m    653\u001b[0m j \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandint(\u001b[39m0\u001b[39m, w \u001b[39m-\u001b[39m tw \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, size\u001b[39m=\u001b[39m(\u001b[39m1\u001b[39m,))\u001b[39m.\u001b[39mitem()\n\u001b[0;32m    654\u001b[0m \u001b[39mreturn\u001b[39;00m i, j, th, tw\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch, gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "print(len(trainloader))\n",
    "epochs = 150\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    lr_sche.step()\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = resnet50(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 30 == 29:    # print every 30 mini-batches\n",
    "            value_tracker(loss_plt, torch.Tensor([running_loss/30]), torch.Tensor([i + epoch*len(trainloader) ]))\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 30))\n",
    "            running_loss = 0.0\n",
    "    \n",
    "    #Check Accuracy\n",
    "    acc = acc_check(resnet50, testloader, epoch, save=1)\n",
    "    value_tracker(acc_plt, torch.Tensor([acc]), torch.Tensor([epoch]))\n",
    "    \n",
    "\n",
    "print('Finished Training') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Accuracy Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 72 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = resnet50(images)\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        \n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
